{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe5b72b",
   "metadata": {},
   "source": [
    "### üìåACTIVIDAD 5: REGRESI√ìN A PARTIR DE FOTOGRAF√çAS\n",
    "\n",
    "#### DEFINIR PROBLEMA Y RECOPILAR DATOS\n",
    "\n",
    "Crea el notebook saa_u03_p01_a5-<tus_iniciales>.ipynb donde entregar esta actividad. Necesitamos\n",
    "consensuar por votaci√≥n 2 posibles problemas (lo que escoja la mayor√≠a de la clase gana) m√°s que\n",
    "nada por obtener suficiente cantidad de datos de alguno de los problemas:\n",
    "\n",
    "\n",
    "b) Predecir la peligrosidad de un animal en un rango de 0 a 10: 10 significa que te puede\n",
    "matar o desgraciar si te engancha y 0 que no te va a da√±ar (al menos en principio). En caso de\n",
    "escoger esta opci√≥n cada uno buscar√°, procesar√° y aportar√° 10 fotograf√≠as de cabezas de\n",
    "animales de todo tipo (serpientes, insectos, felinos, osos, tiburones, ovejas, gatitos, ‚Ä¶) con el\n",
    "nombre del fichero siguiendo el formato \"peligo_<JMP>-<num_foto>.jpg\" o bien\n",
    "formato \"peligo_<JMP>-<num_foto>.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80779130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Se guardaron 109 im√°genes procesadas en 'jmp_imagenes.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Ruta a la carpeta de im√°genes\n",
    "carpeta_imagenes = \"peligro/\"\n",
    "archivo_salida = \"jmp_imagenes.csv\"\n",
    "\n",
    "# Aceptar .jpg, .jpeg o .png que comienzan con d√≠gitos (como \"10_jororo-1.png\")\n",
    "patron = r\"^\\d+.*\\.(jpe?g|png)$\"\n",
    "\n",
    "datos_procesados = []\n",
    "\n",
    "for nombre_archivo in os.listdir(carpeta_imagenes):\n",
    "    if not re.match(patron, nombre_archivo, re.IGNORECASE):\n",
    "        continue\n",
    "\n",
    "    ruta_completa = os.path.join(carpeta_imagenes, nombre_archivo)\n",
    "\n",
    "    try:\n",
    "        edad = int(nombre_archivo.split(\"_\")[0])  # Extrae '10' de '10_jororo-1.png'\n",
    "    except ValueError:\n",
    "        print(f\"‚ùå No se pudo extraer la edad de: {nombre_archivo}\")\n",
    "        continue\n",
    "\n",
    "    imagen = cv2.imread(ruta_completa, cv2.IMREAD_GRAYSCALE)\n",
    "    if imagen is None:\n",
    "        print(f\"‚ùå No se pudo leer la imagen: {nombre_archivo}\")\n",
    "        continue\n",
    "\n",
    "    imagen_escalada = cv2.resize(imagen, (92, 112), interpolation=cv2.INTER_AREA)\n",
    "    imagen_normalizada = (imagen_escalada / 255.0).astype(np.float32)\n",
    "    datos_procesados.append({\n",
    "        \"edad\": edad,\n",
    "        \"imagen\": imagen_normalizada\n",
    "    })\n",
    "\n",
    "# Verificar si se procesaron im√°genes\n",
    "if not datos_procesados:\n",
    "    print(\"‚ö†Ô∏è No se procesaron im√°genes. Revisa la carpeta y el patr√≥n de nombres.\")\n",
    "    exit()\n",
    "\n",
    "# Guardar en CSV\n",
    "df = pd.DataFrame({\n",
    "    \"edad\": [d[\"edad\"] for d in datos_procesados],\n",
    "    \"imagen\": [\",\".join(map(str, d[\"imagen\"].ravel())) for d in datos_procesados]\n",
    "})\n",
    "df.to_csv(archivo_salida, index=False)\n",
    "print(f\"‚úÖ Se guardaron {len(df)} im√°genes procesadas en '{archivo_salida}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4a10b",
   "metadata": {},
   "source": [
    "Lo que hace el c√≥digo es definir rutas (que debes adaptar para tu uso) en las variables carpeta (ruta\n",
    "relativa para alcanzar el lugar donde est√°n las im√°genes) y archivo_salida (pathname relativo que\n",
    "define el archivo .csv donde se van a guardar los datos).\n",
    "\n",
    "Las im√°genes de carpeta se transforman usando la librer√≠a opencv (quiz√°s debas instalarla) en\n",
    "informaci√≥n num√©rica de la siguiente manera: obtendremos una imagen en escala de grises de\n",
    "dimensiones 92x112 p√≠xels (ancho x alto) que se almacenan como valores float de 32 bits sin signo\n",
    "entre 0 y 256 normalizados a float en el intervalo [0,1]. La columna target de cada foto ser√° la primera\n",
    "caracter√≠stica del dataset. Por ejemplo podemos tener ficheros como estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c1f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Edad: 0, Imagen shape: (112, 92)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(archivo_salida)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"‚ö†Ô∏è El archivo CSV est√° vac√≠o.\")\n",
    "    exit()\n",
    "\n",
    "df[\"imagen\"] = df[\"imagen\"].apply(lambda x: np.array(list(map(float, x.split(',')))).reshape(112, 92))\n",
    "\n",
    "# Mostrar la primera imagen\n",
    "edad = df.iloc[0][\"edad\"]\n",
    "imagen = df.iloc[0][\"imagen\"]\n",
    "pixel_array = (imagen * 255).astype(np.uint8)\n",
    "\n",
    "print(f\"üñºÔ∏è Edad: {edad}, Imagen shape: {imagen.shape}\")\n",
    "cv2.imshow(f\"Edad: {edad}\", pixel_array)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802f805",
   "metadata": {},
   "source": [
    "Este otro c√≥digo define un m√©todo al que indicas (un array de im√°genes, un array con sus etiquetas y desde que imagen hasta qu√© imagen quieres visualizar). El m√©todo usa matplotlib para visualizarlas a√±adiendo etiquetas con el dato (la edad en este ejemplo) en un recuadro rojo en la esquina superior izquierda) y con el √≠ndice que ocupa en el DataFrame (una caja de color verde en la esquina inferior izquierda).\n",
    "\n",
    "Y aqu√≠ est√° ese otro c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f471bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_imagenes(imgs, targets, desde, hasta):\n",
    "    # configuramos el tama√±o de las im√°genes por pulgadas\n",
    "    fig = plt.figure(figsize=(30, 24))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(desde, hasta):\n",
    "        # graficamos las im√°genes en una matriz de 25x20\n",
    "        p = fig.add_subplot(25, 20, i + 1, xticks=[], yticks=[])\n",
    "        p.imshow(imgs[i], cmap=\"gray\")\n",
    "        # etiquetar im√°genes con target e √≠ndice\n",
    "        p.text(0, 14, str(targets[i]), bbox=dict(facecolor='red', alpha=0.5))\n",
    "        p.text(0, 100, str(i), bbox=dict(facecolor='green', alpha=0.5))\n",
    "    plt.show()\n",
    "\n",
    "print_imagenes(df.iloc[:][\"imagen\"], df.iloc[:][\"edad\"], 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5355f9",
   "metadata": {},
   "source": [
    "#### ENTRENAR VARIOS REGRESORES Y MEDIR SU DESEMPE√ëO\n",
    "\n",
    "Ahora vamos a utilizar varios regresores para ver el desempe√±o que somos capaces de conseguir en esta tarea. Debes probar todos los regresores que importamos en esta figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99573890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e138d2",
   "metadata": {},
   "source": [
    "En primer lugar necesitamos transformar la caracter√≠stica imagen de cada cara en una caracter√≠stica por cada pixel, para ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bdc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar caracter√≠sticas del dataframe\n",
    "y = df['edad']\n",
    "df_pixels = df[\"imagen\"].apply(lambda img: img.flatten()) # Aplana cada imagen\n",
    "df_pixels = pd.DataFrame(df_pixels.tolist()) # Expandir en columnas\n",
    "df_final = pd.concat([df['edad'], df_pixels], axis=1) # Unir con la edad\n",
    "X = df_final.drop(columns=[\"edad\"]) # Caracter√≠sticas (p√≠xeles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a2390",
   "metadata": {},
   "source": [
    "Como es algo que haremos en todos los modelos, voy a pasarte el c√≥digo de un m√©todo que nos ahorrar√° trabajo. Solo tenemos que pasar en cada llamada los valores y_train, y_test, y_train_predicho, y_test_predicho y el nombre del modelo. Los valores reales y las predicciones deben pasarse sin escalar para que se entiendan bien los gr√°ficos. La figura se obtiene con SVR y solo 31 fotos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c54736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_resultado(y_train, y_train_predicho, y_test, y_test_predicho, nombre_modelo=\"modelo\"):\n",
    "    rmse_train = mean_squared_error(y_train, y_train_predicho)**0.5\n",
    "    rmse_test = mean_squared_error(y_test, y_test_predicho)**0.5\n",
    "    print(f\"RMSE en train de ({nombre_modelo}): {rmse_train:.6f}\")\n",
    "    print(f\"RMSE en test de ({nombre_modelo}): {rmse_test:.6f}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_test, y_test, color=\"red\", label=\"Valor real\")\n",
    "    plt.scatter(y_test, y_test_predicho, color=\"blue\", label=\"Valor predicho\")\n",
    "    plt.xlabel(\"edad\")\n",
    "    plt.ylabel(\"edad predicha\")\n",
    "    plt.axvline()\n",
    "    plt.axhline()\n",
    "    plt.title(f\"Valor-predicci√≥n en Test ({nombre_modelo})\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bar_width = 0.35\n",
    "    bars1 = plt.bar(2 - bar_width/2, rmse_train, width=bar_width, label=\"RMSE Train\", color=\"royalblue\")\n",
    "    bars2 = plt.bar(2 + bar_width/2, rmse_test, width=bar_width, label=\"RMSE Test\", color=\"tomato\")\n",
    "\n",
    "    # Anotar valores encima de las barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            yval = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE en train y test\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb39a3",
   "metadata": {},
   "source": [
    "### ENTREGA 9:\n",
    "\n",
    "a) A√±ade a la carpeta compartida tus 10 fotograf√≠as con el formato indicado.\n",
    "\n",
    "b) Adapta el c√≥digo propuesto, lo entregas y lo ejecutas.\n",
    "\n",
    "c) Entrenas y pruebas el modelo SVR.\n",
    "\n",
    "d) Entrenas y pruebas el modelo DecisionTreeRegressor.\n",
    "\n",
    "e) Entrenas y pruebas el modelo KneighborsRegressor.\n",
    "\n",
    "f) Entrenas y pruebas el modelo BaggingRegressor.\n",
    "\n",
    "g) Entrenas y pruebas el modelo RandomForestRegressor.\n",
    "\n",
    "h) Entrenas y pruebas el modelo AdaBoostRegressor.\n",
    "\n",
    "i) Entrenas y pruebas el modelo GradientBoostingRegressor.\n",
    "\n",
    "j) Comenta en cada uno de ellos los ajustes de hiperpar√°metros que has intentado para evitar\n",
    "que tengan underfitting o bien overfitting. Si no consigues solucionarlo deja la mejor\n",
    "configuraci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7606fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 2\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m)\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "modelo_svr = SVR(C=10, epsilon=0.2, kernel='rbf')  # C alto para menos regularizaci√≥n\n",
    "modelo_svr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_svr.predict(X_train)\n",
    "y_test_pred = modelo_svr.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"SVR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D\n",
    "\n",
    "modelo_dt = DecisionTreeRegressor(max_depth=10, min_samples_split=5, random_state=42)\n",
    "modelo_dt.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_dt.predict(X_train)\n",
    "y_test_pred = modelo_dt.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E\n",
    "\n",
    "modelo_knn = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "modelo_knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_knn.predict(X_train)\n",
    "y_test_pred = modelo_knn.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"KNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#F\n",
    "\n",
    "modelo_bag = BaggingRegressor(n_estimators=50, random_state=42)\n",
    "modelo_bag.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_bag.predict(X_train)\n",
    "y_test_pred = modelo_bag.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"Bagging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36049ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G\n",
    "\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_rf.predict(X_train)\n",
    "y_test_pred = modelo_rf.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I\n",
    "\n",
    "modelo_gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "modelo_gb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = modelo_gb.predict(X_train)\n",
    "y_test_pred = modelo_gb.predict(X_test)\n",
    "\n",
    "resumen_resultado(y_train, y_train_pred, y_test, y_test_pred, \"Gradient Boosting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8cfda",
   "metadata": {},
   "source": [
    "#J\n",
    "\n",
    "‚úÖ SVR (Support Vector Regression)\n",
    "\n",
    "Par√°metros ajustados: C=10, epsilon=0.2, kernel='rbf'\n",
    "Problema detectado: Con valores bajos de C (como C=1), el modelo ten√≠a underfitting (poco aprendizaje).\n",
    "Soluci√≥n: Aumentar C mejor√≥ el ajuste. Tambi√©n prob√© con epsilon=0.1, pero sobreajustaba.\n",
    "Resultado final: C=10, epsilon=0.2 es un buen equilibrio entre bias y varianza.\n",
    "\n",
    "\n",
    "‚úÖ DecisionTreeRegressor\n",
    "\n",
    "Par√°metros ajustados: max_depth=10, min_samples_split=5\n",
    "\n",
    "Problema detectado: Sin limitar profundidad (max_depth=None), el modelo ten√≠a overfitting (muy buena en train, muy mala en test).\n",
    "\n",
    "Soluci√≥n: Limitar max_depth a 10 y min_samples_split a 5 redujo el sobreajuste.\n",
    "\n",
    "Resultado final: El modelo qued√≥ m√°s generalizable sin perder mucha precisi√≥n.\n",
    "\n",
    "\n",
    "‚úÖ KNeighborsRegressor\n",
    "\n",
    "Par√°metros ajustados: n_neighbors=5, weights='distance'\n",
    "\n",
    "Problema detectado: Con n_neighbors=1, el modelo sobreajustaba (memoriza los datos).\n",
    "\n",
    "Soluci√≥n: Aumentar a 5 vecinos y usar weights='distance' mejor√≥ bastante.\n",
    "\n",
    "Resultado final: Buen equilibrio entre exactitud y generalizaci√≥n.\n",
    "\n",
    "‚úÖ BaggingRegressor\n",
    "\n",
    "Par√°metros ajustados: n_estimators=50\n",
    "\n",
    "Problema detectado: Con pocos estimadores (n_estimators=10), el modelo era inestable.\n",
    "\n",
    "Soluci√≥n: Aumentar a 50 mejor√≥ estabilidad sin aumentar el sobreajuste.\n",
    "\n",
    "Resultado final: No presenta overfitting grave gracias al bagging.\n",
    "\n",
    "‚úÖ RandomForestRegressor\n",
    "\n",
    "Par√°metros ajustados: n_estimators=100, max_depth=15\n",
    "\n",
    "Problema detectado: Con profundidad sin l√≠mite, el modelo sobreajustaba.\n",
    "\n",
    "Soluci√≥n: Limitar a max_depth=15 reduce varianza.\n",
    "\n",
    "Resultado final: El modelo tiene buena capacidad de predicci√≥n sin overfitting.\n",
    "\n",
    "‚úÖ AdaBoostRegressor\n",
    "\n",
    "Par√°metros ajustados: n_estimators=50, learning_rate=0.8\n",
    "\n",
    "Problema detectado: Con learning_rate=1.0 y m√°s estimadores, el modelo era inestable.\n",
    "\n",
    "Soluci√≥n: Reducir la tasa de aprendizaje a 0.8 dio mejor generalizaci√≥n.\n",
    "\n",
    "Resultado final: Buen rendimiento para datos con ruido moderado.\n",
    "\n",
    "‚úÖ GradientBoostingRegressor\n",
    "\n",
    "Par√°metros ajustados: n_estimators=100, learning_rate=0.1, max_depth=3\n",
    "\n",
    "Problema detectado: Con learning_rate=0.01, hab√≠a underfitting. Con max_depth=5, sobreajustaba.\n",
    "\n",
    "Soluci√≥n: Ajuste intermedio de depth=3 y lr=0.1 logr√≥ equilibrio.\n",
    "\n",
    "Resultado final: Es uno de los modelos m√°s robustos en general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131c4ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
